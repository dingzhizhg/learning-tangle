{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in /root/anaconda3/lib/python3.11/site-packages (2.19.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /root/anaconda3/lib/python3.11/site-packages (from tensorflow) (2.3.1)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /root/anaconda3/lib/python3.11/site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in /root/anaconda3/lib/python3.11/site-packages (from tensorflow) (25.2.10)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /root/anaconda3/lib/python3.11/site-packages (from tensorflow) (0.6.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /root/anaconda3/lib/python3.11/site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /root/anaconda3/lib/python3.11/site-packages (from tensorflow) (18.1.1)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /root/anaconda3/lib/python3.11/site-packages (from tensorflow) (3.4.0)\n",
      "Requirement already satisfied: packaging in /root/anaconda3/lib/python3.11/site-packages (from tensorflow) (23.1)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /root/anaconda3/lib/python3.11/site-packages (from tensorflow) (5.29.5)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /root/anaconda3/lib/python3.11/site-packages (from tensorflow) (2.31.0)\n",
      "Requirement already satisfied: setuptools in /root/anaconda3/lib/python3.11/site-packages (from tensorflow) (68.0.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /root/anaconda3/lib/python3.11/site-packages (from tensorflow) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /root/anaconda3/lib/python3.11/site-packages (from tensorflow) (3.1.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /root/anaconda3/lib/python3.11/site-packages (from tensorflow) (4.7.1)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /root/anaconda3/lib/python3.11/site-packages (from tensorflow) (1.14.1)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /root/anaconda3/lib/python3.11/site-packages (from tensorflow) (1.74.0)\n",
      "Requirement already satisfied: tensorboard~=2.19.0 in /root/anaconda3/lib/python3.11/site-packages (from tensorflow) (2.19.0)\n",
      "Requirement already satisfied: keras>=3.5.0 in /root/anaconda3/lib/python3.11/site-packages (from tensorflow) (3.11.1)\n",
      "Requirement already satisfied: numpy<2.2.0,>=1.26.0 in /root/anaconda3/lib/python3.11/site-packages (from tensorflow) (1.26.4)\n",
      "Requirement already satisfied: h5py>=3.11.0 in /root/anaconda3/lib/python3.11/site-packages (from tensorflow) (3.14.0)\n",
      "Requirement already satisfied: ml-dtypes<1.0.0,>=0.5.1 in /root/anaconda3/lib/python3.11/site-packages (from tensorflow) (0.5.3)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /root/anaconda3/lib/python3.11/site-packages (from tensorflow) (0.37.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /root/anaconda3/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorflow) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /root/anaconda3/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorflow) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /root/anaconda3/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorflow) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /root/anaconda3/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorflow) (2023.7.22)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /root/anaconda3/lib/python3.11/site-packages (from tensorboard~=2.19.0->tensorflow) (3.4.1)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /root/anaconda3/lib/python3.11/site-packages (from tensorboard~=2.19.0->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /root/anaconda3/lib/python3.11/site-packages (from tensorboard~=2.19.0->tensorflow) (2.2.3)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /root/anaconda3/lib/python3.11/site-packages (from astunparse>=1.6.0->tensorflow) (0.38.4)\n",
      "Requirement already satisfied: rich in /root/anaconda3/lib/python3.11/site-packages (from keras>=3.5.0->tensorflow) (14.1.0)\n",
      "Requirement already satisfied: namex in /root/anaconda3/lib/python3.11/site-packages (from keras>=3.5.0->tensorflow) (0.1.0)\n",
      "Requirement already satisfied: optree in /root/anaconda3/lib/python3.11/site-packages (from keras>=3.5.0->tensorflow) (0.17.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /root/anaconda3/lib/python3.11/site-packages (from werkzeug>=1.0.1->tensorboard~=2.19.0->tensorflow) (2.1.1)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /root/anaconda3/lib/python3.11/site-packages (from rich->keras>=3.5.0->tensorflow) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /root/anaconda3/lib/python3.11/site-packages (from rich->keras>=3.5.0->tensorflow) (2.15.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in /root/anaconda3/lib/python3.11/site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: scipy in /root/anaconda3/lib/python3.11/site-packages (1.11.1)\n",
      "Requirement already satisfied: numpy<1.28.0,>=1.21.6 in /root/anaconda3/lib/python3.11/site-packages (from scipy) (1.26.4)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-08 10:48:54.320607: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-08-08 10:48:54.323309: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-08-08 10:48:54.331405: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-08-08 10:48:54.348290: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1754650134.373047  118057 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1754650134.380455  118057 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1754650134.403270  118057 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1754650134.403289  118057 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1754650134.403292  118057 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1754650134.403294  118057 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-08-08 10:48:54.410771: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "%pip install tensorflow\n",
    "%pip install scipy\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import json\n",
    "import os\n",
    "import random\n",
    "from scipy.stats import dirichlet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_image(image):\n",
    "    # 保持numpy数组格式，只进行归一化\n",
    "    return image / 255.0\n",
    "\n",
    "def generate_data(x, y, num_clients, alpha):\n",
    "    num_classes = 10\n",
    "    client_data = {str(i): {'x': [], 'y': []} for i in range(num_clients)}\n",
    "    \n",
    "    for k in range(num_classes):\n",
    "        idx_k = [i for i, label in enumerate(y) if label == k]\n",
    "        random.shuffle(idx_k)\n",
    "        n_k = len(idx_k)\n",
    "        if n_k == 0:\n",
    "            continue\n",
    "            \n",
    "        proportions = dirichlet.rvs(alpha * np.ones(num_clients))[0]\n",
    "        proportions = proportions / proportions.sum()  # 归一化\n",
    "        \n",
    "        # 按比例分配样本数\n",
    "        proportions = (proportions * n_k).astype(int)\n",
    "        \n",
    "        # 改进的修正算法：随机分配剩余样本\n",
    "        remaining = n_k - proportions.sum()\n",
    "        if remaining > 0:\n",
    "            # 随机选择客户端分配剩余样本\n",
    "            indices = np.random.choice(num_clients, remaining, replace=False)\n",
    "            for idx in indices:\n",
    "                proportions[idx] += 1\n",
    "        elif remaining < 0:\n",
    "            # 随机减少样本\n",
    "            indices = np.random.choice(num_clients, abs(remaining), replace=False)\n",
    "            for idx in indices:\n",
    "                if proportions[idx] > 0:\n",
    "                    proportions[idx] -= 1\n",
    "        \n",
    "        # 分配样本\n",
    "        start = 0\n",
    "        for i, count in enumerate(proportions):\n",
    "            if count > 0:\n",
    "                client_data[str(i)]['x'].append(x[idx_k[start:start+count]])\n",
    "                client_data[str(i)]['y'].append(y[idx_k[start:start+count]])\n",
    "            start += count\n",
    "    \n",
    "    # 合并每个客户端的数据\n",
    "    for client_id in client_data:\n",
    "        if client_data[client_id]['x']:\n",
    "            client_data[client_id]['x'] = np.concatenate(client_data[client_id]['x'], axis=0)\n",
    "            client_data[client_id]['y'] = np.concatenate(client_data[client_id]['y'], axis=0)\n",
    "        else:\n",
    "            client_data[client_id]['x'] = np.array([])\n",
    "            client_data[client_id]['y'] = np.array([])\n",
    "    \n",
    "    # 保证每个客户端至少有1个样本\n",
    "    empty_clients = [cid for cid, data in client_data.items() if len(data['x']) == 0]\n",
    "    for cid in empty_clients:\n",
    "        # 从样本最多的客户端借一个\n",
    "        max_cid = max(client_data, key=lambda k: len(client_data[k]['x']))\n",
    "        client_data[cid]['x'] = client_data[max_cid]['x'][:1]\n",
    "        client_data[cid]['y'] = client_data[max_cid]['y'][:1]\n",
    "        client_data[max_cid]['x'] = client_data[max_cid]['x'][1:]\n",
    "        client_data[max_cid]['y'] = client_data[max_cid]['y'][1:]\n",
    "    \n",
    "    return client_data\n",
    "\n",
    "def get_cluster_id(labels):\n",
    "    counts = np.bincount(labels, minlength=10)\n",
    "    return int(np.argmax(counts))\n",
    "\n",
    "# 修改输出格式，确保numpy数组被正确序列化\n",
    "def numpy_to_list(data):\n",
    "    if isinstance(data, np.ndarray):\n",
    "        return data.tolist()\n",
    "    elif isinstance(data, dict):\n",
    "        return {k: numpy_to_list(v) for k, v in data.items()}\n",
    "    elif isinstance(data, list):\n",
    "        return [numpy_to_list(item) for item in data]\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000\n",
      "10000\n"
     ]
    }
   ],
   "source": [
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "y_train = y_train.reshape(-1)\n",
    "y_test = y_test.reshape(-1)\n",
    "\n",
    "# 使用全部数据\n",
    "train_size = int(len(x_train) * 1.0)\n",
    "test_size = int(len(x_test) * 1.0)\n",
    "\n",
    "# train_size = int(len(x_train) * 0.2)\n",
    "# test_size = int(len(x_test) * 0.2)\n",
    "\n",
    "print(train_size)\n",
    "print(test_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 随机选择数据\n",
    "train_indices = np.random.choice(len(x_train), train_size, replace=False)\n",
    "test_indices = np.random.choice(len(x_test), test_size, replace=False)\n",
    "\n",
    "x_train = x_train[train_indices]\n",
    "y_train = y_train[train_indices]\n",
    "x_test = x_test[test_indices]\n",
    "y_test = y_test[test_indices]\n",
    "\n",
    "# 数据预处理并保持numpy数组格式\n",
    "x_train = np.array([preprocess_image(img) for img in x_train])\n",
    "x_test = np.array([preprocess_image(img) for img in x_test])\n",
    "y_train = np.array(y_train)\n",
    "y_test = np.array(y_test)\n",
    "\n",
    "# 生成训练和测试数据\n",
    "num_clients = 100\n",
    "alpha = 0.1  # Dirichlet分布的参数，越小越non-IID\n",
    "\n",
    "train_data = generate_data(x_train, y_train, num_clients, alpha)\n",
    "test_data = generate_data(x_test, y_test, num_clients, alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 为每个客户端生成cluster_id\n",
    "cluster_ids = {client_id: get_cluster_id(data['y']) \n",
    "                for client_id, data in train_data.items()}\n",
    "\n",
    "# 保存数据前转换numpy数组为列表\n",
    "train_output = {\n",
    "    'user_data': numpy_to_list(train_data),\n",
    "    'cluster_ids': list(cluster_ids.values()),\n",
    "    'users': list(train_data.keys())\n",
    "}\n",
    "\n",
    "test_output = {\n",
    "    'user_data': numpy_to_list(test_data),\n",
    "    'cluster_ids': list(cluster_ids.values()),\n",
    "    'users': list(train_data.keys())\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of clients: 100\n",
      "Average training samples per client: 600.0\n",
      "Average test samples per client: 100.0\n",
      "Cluster distribution: [10 13 13 12  9 10 11 11  3  8  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0]\n",
      "\n",
      "每个客户端的数据量:\n",
      "客户端 0: 训练集 150 样本, 测试集 98 样本\n",
      "客户端 1: 训练集 370 样本, 测试集 58 样本\n",
      "客户端 10: 训练集 857 样本, 测试集 114 样本\n",
      "客户端 11: 训练集 786 样本, 测试集 82 样本\n",
      "客户端 12: 训练集 943 样本, 测试集 46 样本\n",
      "客户端 13: 训练集 153 样本, 测试集 353 样本\n",
      "客户端 14: 训练集 44 样本, 测试集 31 样本\n",
      "客户端 15: 训练集 716 样本, 测试集 14 样本\n",
      "客户端 16: 训练集 203 样本, 测试集 58 样本\n",
      "客户端 17: 训练集 131 样本, 测试集 37 样本\n",
      "客户端 18: 训练集 1820 样本, 测试集 41 样本\n",
      "客户端 19: 训练集 1739 样本, 测试集 134 样本\n",
      "客户端 2: 训练集 171 样本, 测试集 36 样本\n",
      "客户端 20: 训练集 159 样本, 测试集 126 样本\n",
      "客户端 21: 训练集 2146 样本, 测试集 6 样本\n",
      "客户端 22: 训练集 22 样本, 测试集 30 样本\n",
      "客户端 23: 训练集 242 样本, 测试集 5 样本\n",
      "客户端 24: 训练集 460 样本, 测试集 2 样本\n",
      "客户端 25: 训练集 88 样本, 测试集 38 样本\n",
      "客户端 26: 训练集 436 样本, 测试集 274 样本\n",
      "客户端 27: 训练集 242 样本, 测试集 52 样本\n",
      "客户端 28: 训练集 1471 样本, 测试集 89 样本\n",
      "客户端 29: 训练集 1094 样本, 测试集 119 样本\n",
      "客户端 3: 训练集 163 样本, 测试集 328 样本\n",
      "客户端 30: 训练集 221 样本, 测试集 28 样本\n",
      "客户端 31: 训练集 2547 样本, 测试集 274 样本\n",
      "客户端 32: 训练集 37 样本, 测试集 115 样本\n",
      "客户端 33: 训练集 893 样本, 测试集 76 样本\n",
      "客户端 34: 训练集 706 样本, 测试集 133 样本\n",
      "客户端 35: 训练集 267 样本, 测试集 22 样本\n",
      "客户端 36: 训练集 233 样本, 测试集 38 样本\n",
      "客户端 37: 训练集 558 样本, 测试集 53 样本\n",
      "客户端 38: 训练集 1742 样本, 测试集 102 样本\n",
      "客户端 39: 训练集 7 样本, 测试集 115 样本\n",
      "客户端 4: 训练集 1201 样本, 测试集 19 样本\n",
      "客户端 40: 训练集 260 样本, 测试集 87 样本\n",
      "客户端 41: 训练集 1675 样本, 测试集 6 样本\n",
      "客户端 42: 训练集 328 样本, 测试集 107 样本\n",
      "客户端 43: 训练集 442 样本, 测试集 194 样本\n",
      "客户端 44: 训练集 551 样本, 测试集 14 样本\n",
      "客户端 45: 训练集 169 样本, 测试集 272 样本\n",
      "客户端 46: 训练集 168 样本, 测试集 386 样本\n",
      "客户端 47: 训练集 689 样本, 测试集 203 样本\n",
      "客户端 48: 训练集 1000 样本, 测试集 55 样本\n",
      "客户端 49: 训练集 524 样本, 测试集 103 样本\n",
      "客户端 5: 训练集 274 样本, 测试集 55 样本\n",
      "客户端 50: 训练集 210 样本, 测试集 56 样本\n",
      "客户端 51: 训练集 179 样本, 测试集 108 样本\n",
      "客户端 52: 训练集 45 样本, 测试集 68 样本\n",
      "客户端 53: 训练集 2029 样本, 测试集 55 样本\n",
      "客户端 54: 训练集 1679 样本, 测试集 4 样本\n",
      "客户端 55: 训练集 21 样本, 测试集 46 样本\n",
      "客户端 56: 训练集 551 样本, 测试集 488 样本\n",
      "客户端 57: 训练集 117 样本, 测试集 142 样本\n",
      "客户端 58: 训练集 25 样本, 测试集 6 样本\n",
      "客户端 59: 训练集 162 样本, 测试集 155 样本\n",
      "客户端 6: 训练集 353 样本, 测试集 55 样本\n",
      "客户端 60: 训练集 20 样本, 测试集 40 样本\n",
      "客户端 61: 训练集 18 样本, 测试集 30 样本\n",
      "客户端 62: 训练集 257 样本, 测试集 63 样本\n",
      "客户端 63: 训练集 22 样本, 测试集 160 样本\n",
      "客户端 64: 训练集 142 样本, 测试集 2 样本\n",
      "客户端 65: 训练集 725 样本, 测试集 95 样本\n",
      "客户端 66: 训练集 224 样本, 测试集 92 样本\n",
      "客户端 67: 训练集 640 样本, 测试集 77 样本\n",
      "客户端 68: 训练集 191 样本, 测试集 168 样本\n",
      "客户端 69: 训练集 1066 样本, 测试集 71 样本\n",
      "客户端 7: 训练集 624 样本, 测试集 91 样本\n",
      "客户端 70: 训练集 23 样本, 测试集 59 样本\n",
      "客户端 71: 训练集 1023 样本, 测试集 271 样本\n",
      "客户端 72: 训练集 252 样本, 测试集 28 样本\n",
      "客户端 73: 训练集 994 样本, 测试集 29 样本\n",
      "客户端 74: 训练集 853 样本, 测试集 162 样本\n",
      "客户端 75: 训练集 1153 样本, 测试集 180 样本\n",
      "客户端 76: 训练集 896 样本, 测试集 37 样本\n",
      "客户端 77: 训练集 1945 样本, 测试集 3 样本\n",
      "客户端 78: 训练集 22 样本, 测试集 315 样本\n",
      "客户端 79: 训练集 1619 样本, 测试集 191 样本\n",
      "客户端 8: 训练集 393 样本, 测试集 20 样本\n",
      "客户端 80: 训练集 388 样本, 测试集 178 样本\n",
      "客户端 81: 训练集 353 样本, 测试集 109 样本\n",
      "客户端 82: 训练集 119 样本, 测试集 88 样本\n",
      "客户端 83: 训练集 119 样本, 测试集 5 样本\n",
      "客户端 84: 训练集 833 样本, 测试集 15 样本\n",
      "客户端 85: 训练集 483 样本, 测试集 93 样本\n",
      "客户端 86: 训练集 224 样本, 测试集 71 样本\n",
      "客户端 87: 训练集 213 样本, 测试集 86 样本\n",
      "客户端 88: 训练集 243 样本, 测试集 287 样本\n",
      "客户端 89: 训练集 938 样本, 测试集 33 样本\n",
      "客户端 9: 训练集 301 样本, 测试集 179 样本\n",
      "客户端 90: 训练集 1136 样本, 测试集 12 样本\n",
      "客户端 91: 训练集 358 样本, 测试集 138 样本\n",
      "客户端 92: 训练集 2159 样本, 测试集 35 样本\n",
      "客户端 93: 训练集 392 样本, 测试集 106 样本\n",
      "客户端 94: 训练集 1893 样本, 测试集 17 样本\n",
      "客户端 95: 训练集 608 样本, 测试集 196 样本\n",
      "客户端 96: 训练集 624 样本, 测试集 164 样本\n",
      "客户端 97: 训练集 758 样本, 测试集 6 样本\n",
      "客户端 98: 训练集 61 样本, 测试集 36 样本\n",
      "客户端 99: 训练集 226 样本, 测试集 151 样本\n"
     ]
    }
   ],
   "source": [
    "# 打印统计信息\n",
    "print(f\"Number of clients: {num_clients}\")\n",
    "print(f\"Average training samples per client: {np.mean([len(data['x']) for data in train_data.values()])}\")\n",
    "print(f\"Average test samples per client: {np.mean([len(data['x']) for data in test_data.values()])}\")\n",
    "print(f\"Cluster distribution: {np.bincount(list(cluster_ids.values()), minlength=100)}\") \n",
    "\n",
    "# 打印每个客户端的数据量\n",
    "print(\"\\n每个客户端的数据量:\")\n",
    "for client_id in sorted(train_data.keys()):\n",
    "    train_samples = len(train_data[client_id]['x'])\n",
    "    test_samples = len(test_data[client_id]['x'])\n",
    "    print(f\"客户端 {client_id}: 训练集 {train_samples} 样本, 测试集 {test_samples} 样本\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建输出目录\n",
    "os.makedirs('/root/learning-tangle/leaf/data/mnist/data/train', exist_ok=True)\n",
    "os.makedirs('/root/learning-tangle/leaf/data/mnist/data/test', exist_ok=True)\n",
    "\n",
    "# 保存数据\n",
    "with open('/root/learning-tangle/leaf/data/mnist/data/train/data.json', 'w') as file:\n",
    "    json.dump(train_output, file)\n",
    "with open('/root/learning-tangle/leaf/data/mnist/data/test/data.json', 'w') as file:\n",
    "    json.dump(test_output, file)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
