{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-21 06:00:24.637084: I tensorflow/core/util/port.cc:111] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-05-21 06:00:24.641380: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-05-21 06:00:24.697069: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-05-21 06:00:24.697101: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-05-21 06:00:24.697159: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-05-21 06:00:24.708176: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-05-21 06:00:24.709232: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-05-21 06:00:25.814737: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import json\n",
    "import os\n",
    "import random\n",
    "from scipy.stats import dirichlet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_image(image):\n",
    "    return (image / 255.0).tolist()  # 转换为列表\n",
    "\n",
    "def generate_data(x, y, num_clients, alpha):\n",
    "    num_classes = 100\n",
    "    client_data = {str(i): {'x': [], 'y': []} for i in range(num_clients)}\n",
    "    \n",
    "    # 为每个类别生成分布\n",
    "    for k in range(num_classes):\n",
    "        # 获取当前类别的所有样本\n",
    "        idx_k = [i for i, label in enumerate(y) if label == k]\n",
    "        random.shuffle(idx_k)\n",
    "        total_samples = len(idx_k)\n",
    "        \n",
    "        # 使用Dirichlet分布生成每个客户端的样本数量\n",
    "        proportions = dirichlet.rvs(alpha * np.ones(num_clients))[0]\n",
    "        proportions = proportions * total_samples\n",
    "        \n",
    "        # 计算每个客户端应该获得的样本数量\n",
    "        proportions = [int(p) for p in proportions]\n",
    "        \n",
    "        # 分配样本给各个客户端\n",
    "        start_idx = 0\n",
    "        for i in range(num_clients):\n",
    "            end_idx = start_idx + proportions[i]\n",
    "            # 直接添加预处理后的图像（已经是列表格式）\n",
    "            client_data[str(i)]['x'].extend([x[idx] for idx in idx_k[start_idx:end_idx]])\n",
    "            client_data[str(i)]['y'].extend([int(y[idx]) for idx in idx_k[start_idx:end_idx]])\n",
    "            start_idx = end_idx\n",
    "    \n",
    "    return client_data\n",
    "\n",
    "def get_cluster_id(labels):\n",
    "    counts = np.bincount(labels, minlength=100)\n",
    "    return int(np.argmax(counts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000\n",
      "10000\n"
     ]
    }
   ],
   "source": [
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.cifar100.load_data()\n",
    "y_train = y_train.reshape(-1)\n",
    "y_test = y_test.reshape(-1)\n",
    "\n",
    "# 使用全部数据\n",
    "train_size = int(len(x_train) * 1.0)\n",
    "test_size = int(len(x_test) * 1.0)\n",
    "\n",
    "# train_size = int(len(x_train) * 0.2)\n",
    "# test_size = int(len(x_test) * 0.2)\n",
    "\n",
    "print(train_size)\n",
    "print(test_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 随机选择数据\n",
    "train_indices = np.random.choice(len(x_train), train_size, replace=False)\n",
    "test_indices = np.random.choice(len(x_test), test_size, replace=False)\n",
    "\n",
    "x_train = x_train[train_indices]\n",
    "y_train = y_train[train_indices]\n",
    "x_test = x_test[test_indices]\n",
    "y_test = y_test[test_indices]\n",
    "\n",
    "# 数据预处理并转换为列表\n",
    "x_train = [preprocess_image(img) for img in x_train]\n",
    "x_test = [preprocess_image(img) for img in x_test]\n",
    "y_train = y_train.tolist()\n",
    "y_test = y_test.tolist()\n",
    "\n",
    "# 生成训练和测试数据\n",
    "num_clients = 100\n",
    "alpha = 100  # Dirichlet分布的参数，越小越non-IID\n",
    "\n",
    "train_data = generate_data(x_train, y_train, num_clients, alpha)\n",
    "test_data = generate_data(x_test, y_test, num_clients, alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 为每个客户端生成cluster_id\n",
    "cluster_ids = {client_id: get_cluster_id(data['y']) \n",
    "                for client_id, data in train_data.items()}\n",
    "\n",
    "# 准备输出数据\n",
    "train_output = {\n",
    "    'user_data': train_data,\n",
    "    'cluster_ids': list(cluster_ids.values()),\n",
    "    'users': list(train_data.keys())\n",
    "}\n",
    "\n",
    "test_output = {\n",
    "    'user_data': test_data,\n",
    "    'cluster_ids': list(cluster_ids.values()),\n",
    "    'users': list(train_data.keys())\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of clients: 100\n",
      "Average training samples per client: 449.82\n",
      "Average test samples per client: 48.67\n",
      "Cluster distribution: [6 4 3 4 2 2 2 3 4 4 1 3 1 1 1 2 4 3 3 1 0 0 1 1 2 1 2 0 1 2 1 2 1 2 0 1 1\n",
      " 3 0 1 0 0 2 0 1 1 1 0 0 1 0 2 0 0 0 1 1 0 1 0 0 0 1 1 0 1 0 0 0 0 0 0 0 1\n",
      " 1 0 0 1 0 0 1 1 0 0 0 1 0 1 0 0 0 0 1 1 0 0 0 0 1 0]\n",
      "\n",
      "每个客户端的数据量:\n",
      "客户端 0: 训练集 448 样本, 测试集 42 样本\n",
      "客户端 1: 训练集 458 样本, 测试集 43 样本\n",
      "客户端 10: 训练集 435 样本, 测试集 42 样本\n",
      "客户端 11: 训练集 449 样本, 测试集 52 样本\n",
      "客户端 12: 训练集 447 样本, 测试集 41 样本\n",
      "客户端 13: 训练集 452 样本, 测试集 51 样本\n",
      "客户端 14: 训练集 445 样本, 测试集 53 样本\n",
      "客户端 15: 训练集 455 样本, 测试集 44 样本\n",
      "客户端 16: 训练集 451 样本, 测试集 56 样本\n",
      "客户端 17: 训练集 450 样本, 测试集 47 样本\n",
      "客户端 18: 训练集 452 样本, 测试集 47 样本\n",
      "客户端 19: 训练集 452 样本, 测试集 49 样本\n",
      "客户端 2: 训练集 450 样本, 测试集 59 样本\n",
      "客户端 20: 训练集 450 样本, 测试集 40 样本\n",
      "客户端 21: 训练集 455 样本, 测试集 47 样本\n",
      "客户端 22: 训练集 443 样本, 测试集 45 样本\n",
      "客户端 23: 训练集 445 样本, 测试集 38 样本\n",
      "客户端 24: 训练集 453 样本, 测试集 48 样本\n",
      "客户端 25: 训练集 448 样本, 测试集 42 样本\n",
      "客户端 26: 训练集 439 样本, 测试集 51 样本\n",
      "客户端 27: 训练集 446 样本, 测试集 47 样本\n",
      "客户端 28: 训练集 458 样本, 测试集 53 样本\n",
      "客户端 29: 训练集 455 样本, 测试集 52 样本\n",
      "客户端 3: 训练集 454 样本, 测试集 47 样本\n",
      "客户端 30: 训练集 450 样本, 测试集 46 样本\n",
      "客户端 31: 训练集 440 样本, 测试集 45 样本\n",
      "客户端 32: 训练集 446 样本, 测试集 54 样本\n",
      "客户端 33: 训练集 456 样本, 测试集 51 样本\n",
      "客户端 34: 训练集 448 样本, 测试集 51 样本\n",
      "客户端 35: 训练集 453 样本, 测试集 50 样本\n",
      "客户端 36: 训练集 453 样本, 测试集 44 样本\n",
      "客户端 37: 训练集 453 样本, 测试集 49 样本\n",
      "客户端 38: 训练集 443 样本, 测试集 57 样本\n",
      "客户端 39: 训练集 448 样本, 测试集 48 样本\n",
      "客户端 4: 训练集 449 样本, 测试集 51 样本\n",
      "客户端 40: 训练集 450 样本, 测试集 55 样本\n",
      "客户端 41: 训练集 458 样本, 测试集 44 样本\n",
      "客户端 42: 训练集 456 样本, 测试集 52 样本\n",
      "客户端 43: 训练集 444 样本, 测试集 47 样本\n",
      "客户端 44: 训练集 448 样本, 测试集 39 样本\n",
      "客户端 45: 训练集 456 样本, 测试集 48 样本\n",
      "客户端 46: 训练集 449 样本, 测试集 43 样本\n",
      "客户端 47: 训练集 453 样本, 测试集 50 样本\n",
      "客户端 48: 训练集 463 样本, 测试集 54 样本\n",
      "客户端 49: 训练集 451 样本, 测试集 54 样本\n",
      "客户端 5: 训练集 445 样本, 测试集 57 样本\n",
      "客户端 50: 训练集 452 样本, 测试集 46 样本\n",
      "客户端 51: 训练集 454 样本, 测试集 44 样本\n",
      "客户端 52: 训练集 456 样本, 测试集 46 样本\n",
      "客户端 53: 训练集 443 样本, 测试集 48 样本\n",
      "客户端 54: 训练集 449 样本, 测试集 59 样本\n",
      "客户端 55: 训练集 453 样本, 测试集 41 样本\n",
      "客户端 56: 训练集 444 样本, 测试集 46 样本\n",
      "客户端 57: 训练集 452 样本, 测试集 47 样本\n",
      "客户端 58: 训练集 455 样本, 测试集 46 样本\n",
      "客户端 59: 训练集 455 样本, 测试集 48 样本\n",
      "客户端 6: 训练集 456 样本, 测试集 50 样本\n",
      "客户端 60: 训练集 451 样本, 测试集 50 样本\n",
      "客户端 61: 训练集 451 样本, 测试集 52 样本\n",
      "客户端 62: 训练集 448 样本, 测试集 55 样本\n",
      "客户端 63: 训练集 456 样本, 测试集 53 样本\n",
      "客户端 64: 训练集 450 样本, 测试集 51 样本\n",
      "客户端 65: 训练集 451 样本, 测试集 47 样本\n",
      "客户端 66: 训练集 453 样本, 测试集 57 样本\n",
      "客户端 67: 训练集 447 样本, 测试集 38 样本\n",
      "客户端 68: 训练集 455 样本, 测试集 50 样本\n",
      "客户端 69: 训练集 449 样本, 测试集 42 样本\n",
      "客户端 7: 训练集 452 样本, 测试集 39 样本\n",
      "客户端 70: 训练集 439 样本, 测试集 52 样本\n",
      "客户端 71: 训练集 450 样本, 测试集 48 样本\n",
      "客户端 72: 训练集 449 样本, 测试集 46 样本\n",
      "客户端 73: 训练集 447 样本, 测试集 55 样本\n",
      "客户端 74: 训练集 453 样本, 测试集 49 样本\n",
      "客户端 75: 训练集 443 样本, 测试集 50 样本\n",
      "客户端 76: 训练集 440 样本, 测试集 40 样本\n",
      "客户端 77: 训练集 448 样本, 测试集 53 样本\n",
      "客户端 78: 训练集 443 样本, 测试集 40 样本\n",
      "客户端 79: 训练集 448 样本, 测试集 49 样本\n",
      "客户端 8: 训练集 443 样本, 测试集 54 样本\n",
      "客户端 80: 训练集 443 样本, 测试集 49 样本\n",
      "客户端 81: 训练集 456 样本, 测试集 50 样本\n",
      "客户端 82: 训练集 452 样本, 测试集 47 样本\n",
      "客户端 83: 训练集 450 样本, 测试集 53 样本\n",
      "客户端 84: 训练集 450 样本, 测试集 56 样本\n",
      "客户端 85: 训练集 448 样本, 测试集 55 样本\n",
      "客户端 86: 训练集 456 样本, 测试集 58 样本\n",
      "客户端 87: 训练集 454 样本, 测试集 53 样本\n",
      "客户端 88: 训练集 438 样本, 测试集 36 样本\n",
      "客户端 89: 训练集 455 样本, 测试集 45 样本\n",
      "客户端 9: 训练集 447 样本, 测试集 47 样本\n",
      "客户端 90: 训练集 451 样本, 测试集 62 样本\n",
      "客户端 91: 训练集 443 样本, 测试集 44 样本\n",
      "客户端 92: 训练集 451 样本, 测试集 43 样本\n",
      "客户端 93: 训练集 453 样本, 测试集 48 样本\n",
      "客户端 94: 训练集 444 样本, 测试集 50 样本\n",
      "客户端 95: 训练集 445 样本, 测试集 49 样本\n",
      "客户端 96: 训练集 461 样本, 测试集 52 样本\n",
      "客户端 97: 训练集 454 样本, 测试集 52 样本\n",
      "客户端 98: 训练集 449 样本, 测试集 55 样本\n",
      "客户端 99: 训练集 445 样本, 测试集 47 样本\n"
     ]
    }
   ],
   "source": [
    "# 打印统计信息\n",
    "print(f\"Number of clients: {num_clients}\")\n",
    "print(f\"Average training samples per client: {np.mean([len(data['x']) for data in train_data.values()])}\")\n",
    "print(f\"Average test samples per client: {np.mean([len(data['x']) for data in test_data.values()])}\")\n",
    "print(f\"Cluster distribution: {np.bincount(list(cluster_ids.values()), minlength=100)}\") \n",
    "\n",
    "# 打印每个客户端的数据量\n",
    "print(\"\\n每个客户端的数据量:\")\n",
    "for client_id in sorted(train_data.keys()):\n",
    "    train_samples = len(train_data[client_id]['x'])\n",
    "    test_samples = len(test_data[client_id]['x'])\n",
    "    print(f\"客户端 {client_id}: 训练集 {train_samples} 样本, 测试集 {test_samples} 样本\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建输出目录\n",
    "os.makedirs('/root/learning-tangle/leaf/data/cifar100/data/train', exist_ok=True)\n",
    "os.makedirs('/root/learning-tangle/leaf/data/cifar100/data/test', exist_ok=True)\n",
    "\n",
    "# 保存数据\n",
    "with open('/root/learning-tangle/leaf/data/cifar100/data/train/data.json', 'w') as file:\n",
    "    json.dump(train_output, file)\n",
    "with open('/root/learning-tangle/leaf/data/cifar100/data/test/data.json', 'w') as file:\n",
    "    json.dump(test_output, file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jupyter",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
